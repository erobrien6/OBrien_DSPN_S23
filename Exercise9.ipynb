{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erobrien6/OBrien_DSPN_S23/blob/main/Exercise9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2W919d2ZXp7"
      },
      "source": [
        "# Exercise 9: Mixed effects"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4nOzVhyZXqK"
      },
      "source": [
        "This homework assignment is designed to give you practice fitting and interpreting mixed effects models. \n",
        "\n",
        "We will be using the **LexicalData.csv** and **Items.csv** files from the *Homework/lexDat* folder in the class GitHub repository again. \n",
        "\n",
        "This data is a subset of the [English Lexicon Project database](https://elexicon.wustl.edu/). It provides the reaction times (in milliseconds) of many subjects as they are presented with letter strings and asked to decide, as quickly and as accurately as possible, whether the letter string is a word or not. The **Items.csv** provides characteristics of the words used, namely frequency (how common is this word?) and length (how many letters?). Unlike in the previous homework, there isn't any missing data in the **LexicalData.csv** file. \n",
        "\n",
        "*Data courtesy of Balota, D.A., Yap, M.J., Cortese, M.J., Hutchison, K.A., Kessler, B., Loftis, B., Neely, J.H., Nelson, D.L., Simpson, G.B., & Treiman, R. (2007). The English Lexicon Project. Behavior Research Methods, 39, 445-459.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DsyBTB6ZXqN"
      },
      "source": [
        "---\n",
        "## 1. Loading and formatting the data (1 point)\n",
        "\n",
        "Load in data from the **LexicalData.csv** and **Items.csv** files. As in the previous homeworks, remove the commas from the reaction times and convert them from strings to numbers. Use `left_join` to add word characteristics `Length` and `Log_Freq_Hal` from **Items** to **LexicalData**. \n",
        "\n",
        "*Note: the `Freq_HAL` variable in **Items.csv** has a similar formatting issue, using string values with commas. We're not going to worry about fixing this since we're only using `Log_Freq_HAL`, which is the natural log transformation of `Freq_HAL`, in this homework.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UnBVazYfZXqP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "70de2c1a-0064-4357-b62f-00c6e8c96e39"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A data.frame: 6 × 7</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>Sub_ID</th><th scope=col>Trial</th><th scope=col>Type</th><th scope=col>D_RT</th><th scope=col>D_Word</th><th scope=col>Outlier</th><th scope=col>D_Zscore</th></tr>\n",
              "\t<tr><th></th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>1</th><td>157</td><td>1</td><td>1</td><td>710  </td><td>browse     </td><td>false</td><td>-0.437</td></tr>\n",
              "\t<tr><th scope=row>2</th><td> 67</td><td>1</td><td>1</td><td>1,094</td><td>refrigerant</td><td>false</td><td> 0.825</td></tr>\n",
              "\t<tr><th scope=row>3</th><td>120</td><td>1</td><td>1</td><td>587  </td><td>gaining    </td><td>false</td><td>-0.645</td></tr>\n",
              "\t<tr><th scope=row>4</th><td> 21</td><td>1</td><td>1</td><td>984  </td><td>cheerless  </td><td>false</td><td> 0.025</td></tr>\n",
              "\t<tr><th scope=row>5</th><td>236</td><td>1</td><td>1</td><td>577  </td><td>pattered   </td><td>false</td><td>-0.763</td></tr>\n",
              "\t<tr><th scope=row>6</th><td>236</td><td>2</td><td>1</td><td>715  </td><td>conjures   </td><td>false</td><td>-0.364</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA data.frame: 6 × 7\n\n| <!--/--> | Sub_ID &lt;int&gt; | Trial &lt;int&gt; | Type &lt;int&gt; | D_RT &lt;chr&gt; | D_Word &lt;chr&gt; | Outlier &lt;chr&gt; | D_Zscore &lt;dbl&gt; |\n|---|---|---|---|---|---|---|---|\n| 1 | 157 | 1 | 1 | 710   | browse      | false | -0.437 |\n| 2 |  67 | 1 | 1 | 1,094 | refrigerant | false |  0.825 |\n| 3 | 120 | 1 | 1 | 587   | gaining     | false | -0.645 |\n| 4 |  21 | 1 | 1 | 984   | cheerless   | false |  0.025 |\n| 5 | 236 | 1 | 1 | 577   | pattered    | false | -0.763 |\n| 6 | 236 | 2 | 1 | 715   | conjures    | false | -0.364 |\n\n",
            "text/latex": "A data.frame: 6 × 7\n\\begin{tabular}{r|lllllll}\n  & Sub\\_ID & Trial & Type & D\\_RT & D\\_Word & Outlier & D\\_Zscore\\\\\n  & <int> & <int> & <int> & <chr> & <chr> & <chr> & <dbl>\\\\\n\\hline\n\t1 & 157 & 1 & 1 & 710   & browse      & false & -0.437\\\\\n\t2 &  67 & 1 & 1 & 1,094 & refrigerant & false &  0.825\\\\\n\t3 & 120 & 1 & 1 & 587   & gaining     & false & -0.645\\\\\n\t4 &  21 & 1 & 1 & 984   & cheerless   & false &  0.025\\\\\n\t5 & 236 & 1 & 1 & 577   & pattered    & false & -0.763\\\\\n\t6 & 236 & 2 & 1 & 715   & conjures    & false & -0.364\\\\\n\\end{tabular}\n",
            "text/plain": [
              "  Sub_ID Trial Type D_RT  D_Word      Outlier D_Zscore\n",
              "1 157    1     1    710   browse      false   -0.437  \n",
              "2  67    1     1    1,094 refrigerant false    0.825  \n",
              "3 120    1     1    587   gaining     false   -0.645  \n",
              "4  21    1     1    984   cheerless   false    0.025  \n",
              "5 236    1     1    577   pattered    false   -0.763  \n",
              "6 236    2     1    715   conjures    false   -0.364  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A data.frame: 6 × 5</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>Occurrences</th><th scope=col>Word</th><th scope=col>Length</th><th scope=col>Freq_HAL</th><th scope=col>Log_Freq_HAL</th></tr>\n",
              "\t<tr><th></th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>1</th><td>1</td><td>synergistic</td><td>11</td><td>284  </td><td>5.649</td></tr>\n",
              "\t<tr><th scope=row>2</th><td>1</td><td>synonymous </td><td>10</td><td>951  </td><td>6.858</td></tr>\n",
              "\t<tr><th scope=row>3</th><td>1</td><td>syntactical</td><td>11</td><td>114  </td><td>4.736</td></tr>\n",
              "\t<tr><th scope=row>4</th><td>1</td><td>synthesis  </td><td> 9</td><td>6,742</td><td>8.816</td></tr>\n",
              "\t<tr><th scope=row>5</th><td>1</td><td>synthesized</td><td>11</td><td>2,709</td><td>7.904</td></tr>\n",
              "\t<tr><th scope=row>6</th><td>1</td><td>synthesizer</td><td>11</td><td>1,390</td><td>7.237</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA data.frame: 6 × 5\n\n| <!--/--> | Occurrences &lt;int&gt; | Word &lt;chr&gt; | Length &lt;int&gt; | Freq_HAL &lt;chr&gt; | Log_Freq_HAL &lt;dbl&gt; |\n|---|---|---|---|---|---|\n| 1 | 1 | synergistic | 11 | 284   | 5.649 |\n| 2 | 1 | synonymous  | 10 | 951   | 6.858 |\n| 3 | 1 | syntactical | 11 | 114   | 4.736 |\n| 4 | 1 | synthesis   |  9 | 6,742 | 8.816 |\n| 5 | 1 | synthesized | 11 | 2,709 | 7.904 |\n| 6 | 1 | synthesizer | 11 | 1,390 | 7.237 |\n\n",
            "text/latex": "A data.frame: 6 × 5\n\\begin{tabular}{r|lllll}\n  & Occurrences & Word & Length & Freq\\_HAL & Log\\_Freq\\_HAL\\\\\n  & <int> & <chr> & <int> & <chr> & <dbl>\\\\\n\\hline\n\t1 & 1 & synergistic & 11 & 284   & 5.649\\\\\n\t2 & 1 & synonymous  & 10 & 951   & 6.858\\\\\n\t3 & 1 & syntactical & 11 & 114   & 4.736\\\\\n\t4 & 1 & synthesis   &  9 & 6,742 & 8.816\\\\\n\t5 & 1 & synthesized & 11 & 2,709 & 7.904\\\\\n\t6 & 1 & synthesizer & 11 & 1,390 & 7.237\\\\\n\\end{tabular}\n",
            "text/plain": [
              "  Occurrences Word        Length Freq_HAL Log_Freq_HAL\n",
              "1 1           synergistic 11     284      5.649       \n",
              "2 1           synonymous  10     951      6.858       \n",
              "3 1           syntactical 11     114      4.736       \n",
              "4 1           synthesis    9     6,742    8.816       \n",
              "5 1           synthesized 11     2,709    7.904       \n",
              "6 1           synthesizer 11     1,390    7.237       "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Occurrences        Word               Length         Freq_HAL        \n",
              " Min.   :1.000   Length:30959       Min.   : 1.000   Length:30959      \n",
              " 1st Qu.:1.000   Class :character   1st Qu.: 6.000   Class :character  \n",
              " Median :2.000   Mode  :character   Median : 8.000   Mode  :character  \n",
              " Mean   :2.022                      Mean   : 7.992                     \n",
              " 3rd Qu.:3.000                      3rd Qu.:10.000                     \n",
              " Max.   :9.000                      Max.   :21.000                     \n",
              "  Log_Freq_HAL   \n",
              " Min.   : 0.000  \n",
              " 1st Qu.: 4.860  \n",
              " Median : 6.332  \n",
              " Mean   : 6.315  \n",
              " 3rd Qu.: 7.856  \n",
              " Max.   :16.214  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     Sub_ID          Trial            Type       D_RT          \n",
              " Min.   :  1.0   Min.   :  1.0   Min.   :1   Length:62610      \n",
              " 1st Qu.: 77.0   1st Qu.:124.0   1st Qu.:1   Class :character  \n",
              " Median :152.0   Median :251.0   Median :1   Mode  :character  \n",
              " Mean   :151.5   Mean   :249.5   Mean   :1                     \n",
              " 3rd Qu.:227.0   3rd Qu.:375.0   3rd Qu.:1                     \n",
              " Max.   :300.0   Max.   :500.0   Max.   :1                     \n",
              "    D_Word            Outlier             D_Zscore       \n",
              " Length:62610       Length:62610       Min.   :-3.03200  \n",
              " Class :character   Class :character   1st Qu.:-0.65300  \n",
              " Mode  :character   Mode  :character   Median :-0.24000  \n",
              "                                       Mean   : 0.03338  \n",
              "                                       3rd Qu.: 0.41600  \n",
              "                                       Max.   :11.56200  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A data.frame: 6 × 9</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>Sub_ID</th><th scope=col>Trial</th><th scope=col>Type</th><th scope=col>D_RT</th><th scope=col>D_Word</th><th scope=col>Outlier</th><th scope=col>D_Zscore</th><th scope=col>Length</th><th scope=col>Log_Freq_HAL</th></tr>\n",
              "\t<tr><th></th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>1</th><td>157</td><td>1</td><td>1</td><td> 710</td><td>browse     </td><td>false</td><td>-0.437</td><td> 6</td><td>8.856</td></tr>\n",
              "\t<tr><th scope=row>2</th><td> 67</td><td>1</td><td>1</td><td>1094</td><td>refrigerant</td><td>false</td><td> 0.825</td><td>11</td><td>4.644</td></tr>\n",
              "\t<tr><th scope=row>3</th><td>120</td><td>1</td><td>1</td><td> 587</td><td>gaining    </td><td>false</td><td>-0.645</td><td> 7</td><td>8.304</td></tr>\n",
              "\t<tr><th scope=row>4</th><td> 21</td><td>1</td><td>1</td><td> 984</td><td>cheerless  </td><td>false</td><td> 0.025</td><td> 9</td><td>2.639</td></tr>\n",
              "\t<tr><th scope=row>5</th><td>236</td><td>1</td><td>1</td><td> 577</td><td>pattered   </td><td>false</td><td>-0.763</td><td> 8</td><td>1.386</td></tr>\n",
              "\t<tr><th scope=row>6</th><td>236</td><td>2</td><td>1</td><td> 715</td><td>conjures   </td><td>false</td><td>-0.364</td><td> 8</td><td>5.268</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA data.frame: 6 × 9\n\n| <!--/--> | Sub_ID &lt;int&gt; | Trial &lt;int&gt; | Type &lt;int&gt; | D_RT &lt;dbl&gt; | D_Word &lt;chr&gt; | Outlier &lt;chr&gt; | D_Zscore &lt;dbl&gt; | Length &lt;int&gt; | Log_Freq_HAL &lt;dbl&gt; |\n|---|---|---|---|---|---|---|---|---|---|\n| 1 | 157 | 1 | 1 |  710 | browse      | false | -0.437 |  6 | 8.856 |\n| 2 |  67 | 1 | 1 | 1094 | refrigerant | false |  0.825 | 11 | 4.644 |\n| 3 | 120 | 1 | 1 |  587 | gaining     | false | -0.645 |  7 | 8.304 |\n| 4 |  21 | 1 | 1 |  984 | cheerless   | false |  0.025 |  9 | 2.639 |\n| 5 | 236 | 1 | 1 |  577 | pattered    | false | -0.763 |  8 | 1.386 |\n| 6 | 236 | 2 | 1 |  715 | conjures    | false | -0.364 |  8 | 5.268 |\n\n",
            "text/latex": "A data.frame: 6 × 9\n\\begin{tabular}{r|lllllllll}\n  & Sub\\_ID & Trial & Type & D\\_RT & D\\_Word & Outlier & D\\_Zscore & Length & Log\\_Freq\\_HAL\\\\\n  & <int> & <int> & <int> & <dbl> & <chr> & <chr> & <dbl> & <int> & <dbl>\\\\\n\\hline\n\t1 & 157 & 1 & 1 &  710 & browse      & false & -0.437 &  6 & 8.856\\\\\n\t2 &  67 & 1 & 1 & 1094 & refrigerant & false &  0.825 & 11 & 4.644\\\\\n\t3 & 120 & 1 & 1 &  587 & gaining     & false & -0.645 &  7 & 8.304\\\\\n\t4 &  21 & 1 & 1 &  984 & cheerless   & false &  0.025 &  9 & 2.639\\\\\n\t5 & 236 & 1 & 1 &  577 & pattered    & false & -0.763 &  8 & 1.386\\\\\n\t6 & 236 & 2 & 1 &  715 & conjures    & false & -0.364 &  8 & 5.268\\\\\n\\end{tabular}\n",
            "text/plain": [
              "  Sub_ID Trial Type D_RT D_Word      Outlier D_Zscore Length Log_Freq_HAL\n",
              "1 157    1     1     710 browse      false   -0.437    6     8.856       \n",
              "2  67    1     1    1094 refrigerant false    0.825   11     4.644       \n",
              "3 120    1     1     587 gaining     false   -0.645    7     8.304       \n",
              "4  21    1     1     984 cheerless   false    0.025    9     2.639       \n",
              "5 236    1     1     577 pattered    false   -0.763    8     1.386       \n",
              "6 236    2     1     715 conjures    false   -0.364    8     5.268       "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# WRITE YOUR CODE HERE\n",
        "# Manually uploaded data to colab due to working directory error\n",
        "df_lexical <- read.csv(\"/content/LexicalData.csv\")\n",
        "df_items <- read.csv(\"/content/Items.csv\")\n",
        "\n",
        "head(df_lexical)\n",
        "head(df_items)\n",
        "summary(df_items)\n",
        "summary(df_lexical)\n",
        "\n",
        "library(tidyverse)\n",
        "library(dplyr)\n",
        "\n",
        "## Remove commas\n",
        "df_lexical$D_RT <- gsub(',','', df_lexical$D_RT)\n",
        "\n",
        "## Make numeric\n",
        "df_lexical$D_RT <- as.numeric(df_lexical$D_RT)\n",
        "\n",
        "## Join task\n",
        "df_final <- left_join(df_lexical, df_items, by = c('D_Word' = 'Word'))\n",
        "# Only include Length and Log_Freq_HAL\n",
        "df_final <- df_final %>%\n",
        "  select(c(1:7, 9, 11))\n",
        "\n",
        "head(df_final)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXy81Viishk1"
      },
      "source": [
        "---\n",
        "## 2. Model fitting (4 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7_gEgkbzFtU"
      },
      "source": [
        "First, fit a linear model with `Log_Freq_HAL` and `Length` as predictors, and `D_RT` as the output. Include an interaction term. Use `summary()` to look at the model output. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "OIOIg-GRz4rN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "dc343ea1-d640-4ded-ebf9-e1327b96b800"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "lm(formula = D_RT ~ Length + Log_Freq_HAL + Length * Log_Freq_HAL, \n",
              "    data = df_final)\n",
              "\n",
              "Residuals:\n",
              "     Min       1Q   Median       3Q      Max \n",
              "-1118.01  -205.23   -86.95    90.77  3147.07 \n",
              "\n",
              "Coefficients:\n",
              "                    Estimate Std. Error t value Pr(>|t|)    \n",
              "(Intercept)         610.1903    14.6678  41.601  < 2e-16 ***\n",
              "Length               47.7531     1.6368  29.175  < 2e-16 ***\n",
              "Log_Freq_HAL         -6.0239     1.9678  -3.061  0.00221 ** \n",
              "Length:Log_Freq_HAL  -2.9421     0.2348 -12.528  < 2e-16 ***\n",
              "---\n",
              "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
              "\n",
              "Residual standard error: 359.1 on 62606 degrees of freedom\n",
              "Multiple R-squared:  0.09473,\tAdjusted R-squared:  0.09469 \n",
              "F-statistic:  2184 on 3 and 62606 DF,  p-value: < 2.2e-16\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# WRITE YOUR CODE HERE\n",
        "linear_model <- lm(D_RT ~ Length + Log_Freq_HAL + Length*Log_Freq_HAL, data = df_final)\n",
        "summary(linear_model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pbeg_JrS3mwU"
      },
      "source": [
        "Now, install `lme4` using `install.packages()` and then load the library. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFSnvvb_re2O"
      },
      "outputs": [],
      "source": [
        "# WRITE YOUR CODE HERE\n",
        "# install.packages('lme4')\n",
        "library('lme4')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZJns7xr41nW"
      },
      "source": [
        "Now fit a mixed effects model that includes the same predictors as the linear model above, as well as random intercepts for `Sub_ID` (i.e., cases where subject ID shifts the RT mean). Use `summary()` to look at the model output. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "8kjwT0je57N7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "outputId": "44092f0c-bf94-47cf-c861-d8e9bcba0e5b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Linear mixed model fit by REML ['lmerMod']\n",
              "Formula: D_RT ~ +Length + Log_Freq_HAL + Length * Log_Freq_HAL + (1 |  \n",
              "    Sub_ID)\n",
              "   Data: df_final\n",
              "\n",
              "REML criterion at convergence: 888235.6\n",
              "\n",
              "Scaled residuals: \n",
              "    Min      1Q  Median      3Q     Max \n",
              "-4.5058 -0.5472 -0.1568  0.3103 10.7381 \n",
              "\n",
              "Random effects:\n",
              " Groups   Name        Variance Std.Dev.\n",
              " Sub_ID   (Intercept) 46333    215.3   \n",
              " Residual             82978    288.1   \n",
              "Number of obs: 62610, groups:  Sub_ID, 299\n",
              "\n",
              "Fixed effects:\n",
              "                    Estimate Std. Error t value\n",
              "(Intercept)         616.8445    17.1522  35.963\n",
              "Length               47.7477     1.3162  36.277\n",
              "Log_Freq_HAL         -7.4374     1.5830  -4.698\n",
              "Length:Log_Freq_HAL  -2.8778     0.1888 -15.239\n",
              "\n",
              "Correlation of Fixed Effects:\n",
              "            (Intr) Length L_F_HA\n",
              "Length      -0.656              \n",
              "Log_Frq_HAL -0.645  0.917       \n",
              "Lng:L_F_HAL  0.582 -0.923 -0.942"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# WRITE YOUR CODE HERE\n",
        "mixed_model <- lmer(D_RT ~ + Length + Log_Freq_HAL + Length*Log_Freq_HAL + (1|Sub_ID), data = df_final)\n",
        "summary(mixed_model)\n",
        "\n",
        "# Linear Regression T Values\n",
        "## Length: 29.175\n",
        "## Log: -3.061\n",
        "## Interaction: -12.528\n",
        "\n",
        "# ME T Values\n",
        "## Length: 36.277\n",
        "## Log: -4.698\n",
        "## Interaction: -15.239\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vfb_ovk7JFGt"
      },
      "source": [
        "---\n",
        "## 3. Model assessment (4 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7B1Ux6RHGjy"
      },
      "source": [
        "Compare the three t-values for the fixed effects and the mixed effects models. How do they differ, and why? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCi5gYOeHo6m"
      },
      "source": [
        "> *All of the t-values in both models yield significant effects (p < .05). However, the mixed effects model t-values are all greater in magnitude than the t-values of the linear regression model (for Length, it increased from 29.2 to 36.3, for Log_Freq_HAL it decreased from -3.1 to -4.7, and for the interaction term it decreased from -12.5 to -15.2). This difference suggests that by controlling for subject effects, the p-values become smaller, and we are getting a less conservative model fit on the fixed effects.* \n",
        "> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hukKG1AbGqXM"
      },
      "source": [
        "Use the Aikeke Information Criterion (AIC) to compare these two models. Which one is better? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "KMDg8qb5FhJz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "dbe6780d-77d3-42a2-afae-f10a82492a0c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A data.frame: 2 × 2</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>df</th><th scope=col>AIC</th></tr>\n",
              "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>linear_model</th><td>5</td><td>914436.4</td></tr>\n",
              "\t<tr><th scope=row>mixed_model</th><td>6</td><td>888247.6</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA data.frame: 2 × 2\n\n| <!--/--> | df &lt;dbl&gt; | AIC &lt;dbl&gt; |\n|---|---|---|\n| linear_model | 5 | 914436.4 |\n| mixed_model | 6 | 888247.6 |\n\n",
            "text/latex": "A data.frame: 2 × 2\n\\begin{tabular}{r|ll}\n  & df & AIC\\\\\n  & <dbl> & <dbl>\\\\\n\\hline\n\tlinear\\_model & 5 & 914436.4\\\\\n\tmixed\\_model & 6 & 888247.6\\\\\n\\end{tabular}\n",
            "text/plain": [
              "             df AIC     \n",
              "linear_model 5  914436.4\n",
              "mixed_model  6  888247.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "-26188.8233715765"
            ],
            "text/markdown": "-26188.8233715765",
            "text/latex": "-26188.8233715765",
            "text/plain": [
              "[1] -26188.82"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# WRITE YOUR CODE HERE\n",
        "\n",
        "ic = AIC(linear_model, mixed_model)\n",
        "ic\n",
        "diff(ic$AIC)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4oTfsYmIvYt"
      },
      "source": [
        "> *The mixed effects model appears to be a better fit than the linear model because the AIC is lower, indicating that the ME model can explain more variance in reaction time even when accounting for increased complexity.* \n",
        "> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARF2PF2yLXkZ"
      },
      "source": [
        "---\n",
        "##  4. Reflection (1 point)\n",
        "\n",
        "What other random effects could be controlled for in this data set? \n",
        "\n",
        "> *One example of another random effect that could be controlled for is by trial number. This could be relevant if we were interested in assessing whether particpants experienced task fatigue and performed worse in general after their first trial; conversely, we could control for practice effects and potential improvement over trials.* \n",
        "> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4MPECMmZXqe"
      },
      "source": [
        "**DUE:** 5pm EST, March 15, 2023"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9GUofXN4BVy"
      },
      "source": [
        "**IMPORTANT** Did you collaborate with anyone on this assignment? If so, list their names here. \n",
        "> *Someone's Name*"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "language_info": {
      "codemirror_mode": "r",
      "file_extension": ".r",
      "mimetype": "text/x-r-source",
      "name": "R",
      "pygments_lexer": "r",
      "version": "4.2.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}